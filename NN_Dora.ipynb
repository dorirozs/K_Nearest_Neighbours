{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1203a98",
   "metadata": {},
   "source": [
    "Relevant imports and loading the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "01ee8ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "# Iris dataset loaded, ready to use\n",
    "X = iris['data'] # Array of data values\n",
    "y = iris['target'] # Array of corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "19ebf46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the ionosphere dataset from text file\n",
    "A = np.genfromtxt(\"ionosphere.txt\", delimiter=\",\",\n",
    "usecols=np.arange(34)) # The first 34 columns contain the data values\n",
    "\n",
    "B = np.genfromtxt(\"ionosphere.txt\", delimiter=\",\",\n",
    "usecols=34, dtype='int') # The last column contains the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c0f6d7",
   "metadata": {},
   "source": [
    "Splitting the datasets into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "80d4ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting iris dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "y, random_state=1202)\n",
    "\n",
    "# Splitting ionosphere dataset\n",
    "A_train, A_test, B_train, B_test = train_test_split(A,\n",
    "B, random_state=1202)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c751ca3",
   "metadata": {},
   "source": [
    "###### The Euclidean distance function - calculates distance between the given point and a vector. Returns an array of all the distances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a814ffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(point, data):\n",
    "    distance = 0.0\n",
    "    distances = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        distance = np.linalg.norm(point - data[i])\n",
    "        distances.append(distance)\n",
    "    return distances # Array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5bc67",
   "metadata": {},
   "source": [
    "#### A simple bubble sort to sort the array of distances in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "adb187c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bubble_sort_ascending(distances_and_indexes):\n",
    "    n = len(distances_and_indexes)\n",
    "\n",
    "    for i in range( n - 1 ) :\n",
    "        flag = 0\n",
    "        for j in range(n - 1) :\n",
    "            \n",
    "            if distances_and_indexes[j] > distances_and_indexes[j + 1] : \n",
    "                tmp = distances_and_indexes[j]\n",
    "                distances_and_indexes[j] = distances_and_indexes[j + 1]\n",
    "                distances_and_indexes[j + 1] = tmp\n",
    "                flag = 1\n",
    "\n",
    "        if flag == 0:\n",
    "            break\n",
    "\n",
    "    return distances_and_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18403045",
   "metadata": {},
   "source": [
    "###### The array sorting function - sorts the array of distances in ascending order, returns the indexes of those points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6926c0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_least_distances(distances, k):\n",
    "    distances_and_indexes = []\n",
    "    \n",
    "    # This makes a new list with sub-lists containing the distance value and adding an indexing value (to keep track of what point the distance belonged to later)\n",
    "    for i in range(len(distances)):\n",
    "        distances_and_indexes.append([distances[i],i])\n",
    "    \n",
    "    distances_and_indexes_sorted = []\n",
    "    distances_and_indexes_sorted = bubble_sort_ascending(distances_and_indexes) # Using bubble sort on the [distance,index] array\n",
    "    \n",
    "    nearest_neighbour_indexes = [] \n",
    "    \n",
    "    # Making an array of the indexes of the k lest distances (Need indexes to pair up to original points)\n",
    "    for i in range(k):\n",
    "        nearest_neighbour_indexes.append(distances_and_indexes_sorted[i][1])\n",
    "        \n",
    "    return nearest_neighbour_indexes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8328e81a",
   "metadata": {},
   "source": [
    "###### Function that finds the labels and values of the nearest neighbours by their indexes. Returns 2 arrays: an array of labels and an array of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "186acbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbours(neighbour_indexes, data, labels):\n",
    "    nearest_n = []\n",
    "    nearest_n_labels = []\n",
    "    \n",
    "    for i in range(len(neighbour_indexes)):\n",
    "        current_index = neighbour_indexes[i]\n",
    "        nearest_n.append(data[current_index])\n",
    "        nearest_n_labels.append(labels[current_index])\n",
    "    \n",
    "    return nearest_n_labels, nearest_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4d3b1e",
   "metadata": {},
   "source": [
    "###### The majority vote function - If K > 1 a vote is needed: the most popular label of the nearest neighbours will be the prediction label of the new point.\n",
    "Returns a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0cd70e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(nearest_labels):\n",
    "    labels = []\n",
    "    majority_vote = ''\n",
    "    majority_count = None # No value assigned yet\n",
    "    \n",
    "    # Add all labels of all of the k nearest neighbours to an array\n",
    "    for i in range(len(nearest_labels)):\n",
    "        if nearest_labels[i] not in labels:\n",
    "            labels.append(nearest_labels[i])\n",
    "    \n",
    "    # Loops through array of all labels, decides which label is of highest frequency\n",
    "    for i in range(len(labels)):\n",
    "        counted = nearest_labels.count(labels[i])\n",
    "        if majority_count == None: # If no value assigned yet, first label is the majority\n",
    "            majority_vote = labels[i]\n",
    "            majority_count = counted\n",
    "        elif majority_count < counted: # Checks if it had exceeded the previous majority counted label\n",
    "            majority_vote = labels[i]\n",
    "            majority_count = counted\n",
    "        elif majority_count == counted: # In case of a tie, assigns current majority label\n",
    "            majority_vote = labels[i]\n",
    "            \n",
    "    return majority_vote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a621800",
   "metadata": {},
   "source": [
    "##### The K Nearest neighbours algorithm - pieces together all of the above functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c878da4e",
   "metadata": {},
   "source": [
    "Finds k nearest neighbours of point input, returns single value: the predicted label of the new point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ee94a017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_neighbours(point, data, labels, k):\n",
    "    \n",
    "    if k == 0:\n",
    "        print(\"Expecting K > 0 input.\")\n",
    "        return 0\n",
    "    elif (k > len(data)):\n",
    "        print(\"Expecting K < \", len(data),\" input.\")\n",
    "        return 0\n",
    "    else:\n",
    "        \n",
    "        neighbour_indexes = []\n",
    "        neighbour_labels = []\n",
    "        neighbour_data = []\n",
    "    \n",
    "        neighbour_indexes = k_least_distances(euclidean_distance(point, data), k) # Gets the indexes of the k nearest neighbours\n",
    "    \n",
    "        neighbour_labels, neighbour_data = nearest_neighbours(neighbour_indexes, data, labels) # Gets data and labels of neighbours\n",
    "    \n",
    "        point_label = majority_vote(neighbour_labels) # Calculates the predicted label of 'point' using majority vote\n",
    "    \n",
    "        return point_label # returns predicted label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dbe884",
   "metadata": {},
   "source": [
    "## Testing for the iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c23b5b",
   "metadata": {},
   "source": [
    "Made the testing sequence into a function - easier to call it mutliple times with different values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "820cdd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iris_predictions(X_test, X_train, y_test, y_train, k):\n",
    "    if k == 0:\n",
    "        print(\"Expecting K > 0 input.\")\n",
    "        return 0\n",
    "    elif k > len(X_train):\n",
    "        print(\"Expecting K < \", len(X_train)+1, \" input.\")\n",
    "        return 0\n",
    "    else:\n",
    "        X_test_predicted_labels = []\n",
    "        X_test_predicted_compare = []\n",
    "        n_test_errors = 0\n",
    "        test_error_rate = 0.0\n",
    "\n",
    "        for i in range(len(X_test)):\n",
    "            X_test_predicted_labels.append(k_nearest_neighbours(X_test[i], X_train, y_train, k))\n",
    "\n",
    "        for j in range(len(X_test_predicted_labels)):\n",
    "            if (X_test_predicted_labels[j] == y_test[j]):\n",
    "                X_test_predicted_compare.append(\"True\")\n",
    "            else:\n",
    "                X_test_predicted_compare.append(\"False\")\n",
    "                n_test_errors += 1\n",
    "\n",
    "        test_error_rate = round(n_test_errors/len(X_test),5)\n",
    "    \n",
    "        print(\"For K = \", k, \"\\n\")\n",
    "        print(\"The predicted labels: \\n\", X_test_predicted_labels, \"\\n\")\n",
    "        print(\"The predicted labels compared to the true labels: \\n\", X_test_predicted_compare, \"\\n\")\n",
    "        print(\"Number of test errors: \", n_test_errors, \"\\n\")\n",
    "        print(\"Test error rate: \", test_error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f860f25c",
   "metadata": {},
   "source": [
    "### a) iris for K = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a0284c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For K =  1 \n",
      "\n",
      "The predicted labels: \n",
      " [1, 2, 1, 0, 0, 2, 0, 1, 2, 0, 0, 1, 2, 1, 1, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 1, 2, 1, 0, 1, 1, 0, 0, 1, 0, 1, 2, 2] \n",
      "\n",
      "The predicted labels compared to the true labels: \n",
      " ['True', 'True', 'True', 'True', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True'] \n",
      "\n",
      "Number of test errors:  2 \n",
      "\n",
      "Test error rate:  0.05263\n"
     ]
    }
   ],
   "source": [
    "iris_predictions(X_test, X_train, y_test, y_train, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481cf57a",
   "metadata": {},
   "source": [
    "### b) iris for K = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e90bc6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For K =  3 \n",
      "\n",
      "The predicted labels: \n",
      " [1, 2, 1, 0, 0, 2, 0, 2, 2, 0, 0, 1, 2, 1, 1, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 1, 2, 1, 0, 1, 1, 0, 0, 1, 0, 1, 2, 2] \n",
      "\n",
      "The predicted labels compared to the true labels: \n",
      " ['True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True'] \n",
      "\n",
      "Number of test errors:  1 \n",
      "\n",
      "Test error rate:  0.02632\n"
     ]
    }
   ],
   "source": [
    "iris_predictions(X_test, X_train, y_test, y_train, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c87e379",
   "metadata": {},
   "source": [
    "### iris for general K (any K) and handling invalid K inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "424441ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting K > 0 input.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_predictions(X_test, X_train, y_test, y_train, 0) # # Handling K = 0 --> invalid input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9d7c13eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For K =  12 \n",
      "\n",
      "The predicted labels: \n",
      " [1, 2, 1, 0, 0, 2, 0, 2, 2, 0, 0, 1, 2, 1, 1, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 1, 2, 1, 0, 1, 1, 0, 0, 1, 0, 1, 2, 2] \n",
      "\n",
      "The predicted labels compared to the true labels: \n",
      " ['True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True'] \n",
      "\n",
      "Number of test errors:  1 \n",
      "\n",
      "Test error rate:  0.02632\n"
     ]
    }
   ],
   "source": [
    "iris_predictions(X_test, X_train, y_test, y_train, 12) # Works for any general K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2e651638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For K =  112 \n",
      "\n",
      "The predicted labels: \n",
      " [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] \n",
      "\n",
      "The predicted labels compared to the true labels: \n",
      " ['False', 'True', 'False', 'False', 'False', 'True', 'False', 'True', 'True', 'False', 'False', 'False', 'True', 'False', 'False', 'False', 'False', 'True', 'False', 'False', 'False', 'False', 'False', 'True', 'False', 'False', 'True', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'False', 'True', 'True'] \n",
      "\n",
      "Number of test errors:  28 \n",
      "\n",
      "Test error rate:  0.73684\n"
     ]
    }
   ],
   "source": [
    "iris_predictions(X_test, X_train, y_test, y_train, len(X_train)) # Testing for maximum valid value of K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "8b06b6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting K <  113  input.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_predictions(X_test, X_train, y_test, y_train, len(X_train)+1) # Handling K > length of data array --> invalid input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa00ff6d",
   "metadata": {},
   "source": [
    "## Testing for the ionosphere dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf68032",
   "metadata": {},
   "source": [
    "Made the testing sequence into a function - easier to call it mutliple times with different values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "566fb366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ionosphere_predictions(A_test, A_train, B_test, B_train, k):\n",
    "    if k == 0:\n",
    "        print(\"Expecting K > 0 input.\")\n",
    "        return 0\n",
    "    elif k > len(A_train):\n",
    "        print(\"Expecting K < \", len(A_train)+1, \" input.\")\n",
    "        return 0\n",
    "    else:\n",
    "        A_test_predicted_labels = []\n",
    "        A_test_predicted_compare = []\n",
    "        n_test_errors = 0\n",
    "        test_error_rate = 0.0\n",
    "\n",
    "        for i in range(len(A_test)):\n",
    "            A_test_predicted_labels.append(k_nearest_neighbours(A_test[i], A_train, B_train, k))\n",
    "\n",
    "        for j in range(len(A_test_predicted_labels)):\n",
    "            if (A_test_predicted_labels[j] == B_test[j]):\n",
    "                A_test_predicted_compare.append(\"True\")\n",
    "            else:\n",
    "                A_test_predicted_compare.append(\"False\")\n",
    "                n_test_errors += 1\n",
    "\n",
    "        test_error_rate = round(n_test_errors/len(A_test),5)\n",
    "    \n",
    "        print(\"For K = \", k, \"\\n\")\n",
    "        print(\"The predicted labels: \\n\", A_test_predicted_labels, \"\\n\")\n",
    "        print(\"The predicted labels compared to the true labels: \\n\", A_test_predicted_compare, \"\\n\")\n",
    "        print(\"Number of test errors: \", n_test_errors, \"\\n\")\n",
    "        print(\"Test error rate: \", test_error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39474b61",
   "metadata": {},
   "source": [
    "### c) ionosphere for K = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "554a48cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For K =  1 \n",
      "\n",
      "The predicted labels: \n",
      " [-1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, 1, 1] \n",
      "\n",
      "The predicted labels compared to the true labels: \n",
      " ['True', 'False', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'False', 'False', 'True', 'True', 'True', 'True', 'False', 'True', 'False', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'False', 'True', 'False', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'True', 'False', 'True', 'False', 'True', 'True', 'True', 'True', 'False', 'True', 'False', 'True', 'True'] \n",
      "\n",
      "Number of test errors:  16 \n",
      "\n",
      "Test error rate:  0.18182\n"
     ]
    }
   ],
   "source": [
    "ionosphere_predictions(A_test, A_train, B_test, B_train, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c70fcec",
   "metadata": {},
   "source": [
    "### d) ionosphere for K = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "171c4f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For K =  3 \n",
      "\n",
      "The predicted labels: \n",
      " [-1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1] \n",
      "\n",
      "The predicted labels compared to the true labels: \n",
      " ['True', 'False', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'False', 'False', 'False', 'True', 'True', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'True', 'True', 'True', 'False', 'True', 'False', 'True', 'True'] \n",
      "\n",
      "Number of test errors:  13 \n",
      "\n",
      "Test error rate:  0.14773\n"
     ]
    }
   ],
   "source": [
    "ionosphere_predictions(A_test, A_train, B_test, B_train, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd6fd50",
   "metadata": {},
   "source": [
    "### ionosphere for general K (any K) and handling invalid K inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "de8bb8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting K > 0 input.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ionosphere_predictions(A_test, A_train, B_test, B_train, 0) # Handling K = 0 --> invalid input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "66391068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For K =  18 \n",
      "\n",
      "The predicted labels: \n",
      " [-1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] \n",
      "\n",
      "The predicted labels compared to the true labels: \n",
      " ['True', 'False', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'False', 'False', 'False', 'True', 'True', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'False', 'False', 'True', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'False', 'True', 'True', 'False', 'True', 'True', 'False', 'True', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'False', 'True', 'True', 'False', 'False', 'False', 'True', 'True'] \n",
      "\n",
      "Number of test errors:  20 \n",
      "\n",
      "Test error rate:  0.22727\n"
     ]
    }
   ],
   "source": [
    "ionosphere_predictions(A_test, A_train, B_test, B_train, 18) # General K input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6093ea12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For K =  263 \n",
      "\n",
      "The predicted labels: \n",
      " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] \n",
      "\n",
      "The predicted labels compared to the true labels: \n",
      " ['False', 'False', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'True', 'False', 'False', 'True', 'True', 'True', 'False', 'False', 'False', 'True', 'True', 'True', 'False', 'True', 'False', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'False', 'False', 'True', 'True', 'False', 'True', 'False', 'True', 'True', 'False', 'True', 'True', 'True', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'True', 'False', 'True', 'False', 'False', 'True', 'True', 'False', 'False', 'True', 'True', 'True', 'False', 'True', 'True', 'True', 'False', 'False', 'False', 'True', 'True', 'False', 'True', 'True', 'True', 'False', 'True', 'True', 'False', 'False', 'False', 'True', 'True'] \n",
      "\n",
      "Number of test errors:  31 \n",
      "\n",
      "Test error rate:  0.35227\n"
     ]
    }
   ],
   "source": [
    "ionosphere_predictions(A_test, A_train, B_test, B_train, len(A_train)) # Testing for maxium valid K input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3f4d9738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting K <  264  input.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ionosphere_predictions(A_test, A_train, B_test, B_train, len(A_train)+1) # Handling K > length of data array --> invalid input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4b47c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
